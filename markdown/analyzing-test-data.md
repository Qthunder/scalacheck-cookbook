<span id="_Toc300926424" class="anchor"><span id="_Toc188339621" class="anchor"></span></span>Analyzing test data
=================================================================================================================

In addition to generating test data, ScalaCheck can also collect the data, group it using custom rules, and report the statistics upon test completion. This feature is useful to visualize, as part of the output of the property check execution, whether ScalaCheck is using sufficiently equally distributed data.

The two key methods for data gathering and grouping are ```classify``` and ```collect```, both part of the ```Prop``` companion object. When using either one of these two methods, ScalaCheck will print the results of the grouping to the console upon completion of the property check.

The ```collect``` method is the easiest way to collect all the data generated by ScalaCheck, as it can use any kind of criteria to group our data. Data can be grouped directly based on its actual values, such as the example below where the input of the property is used as the grouping criterion:

```scala
object DataCollectionSpecification extends Properties("Data collection examples") {
  property("data collection spec") = forAll { (r: Rectangle) =>
    collect((r.width, r.height)) {
      r.areaCorrect == (r.width \* r.height)
    }
  }
}
```

<span id="_Toc300926425" class="anchor"></span>

In the previous example, the console output will show a long list of pairs of height and width, each one of them with a 1% frequency, similar to this:

```
+ Data collection examples.data collection spec: OK, passed 100 tests.
> Collected test data:
1% (1059.0,3685.0)
1% (8004.0,2400.0)
1% (5543.0,751.0)
1% (2941.0,6644.0)
1% (277.0,9994.0)
1% (973.0,289.0)
1% (7662.0,3924.0)
(...up to 100 lines...)
```

It is clear that a smarter mechanism for grouping the data is needed here. In the case of the ```collect``` method, ScalaCheck will use the values provided to the method call to group the data, so it’s possible to provide a custom function of the input data that provides for coarser grouping of the data. In this case, we are going to group rectangles in three categories based on the size their perimeter ("small", "medium" and "large") using the following function:

```scala
val collector: PartialFunction[Rectangle, String] = {
  case r if r.perimeter < 10000 => "small"
  case r if r.perimeter > 10000 && r.perimeter < 25000 => "medium"
  case r if r.perimeter > 25000 => "large"
}
```

A partial function is used here as opposed to a traditional function because partial functions allow us to directly plug in pattern matching with guards that are used to define how our input data gets classified. (This partial function is actually a full function, but if we had declared it as a full function we would have need to include an artificial default case, e.g., ```case _ => "".``` to avoid a " match is not exhaustive!" warning. Alternatively, the function could be defined using a chain of if…else blocks. The partial function syntax is more concise and clear in this situation.) The return value of the function is a string as this function must always return something which is used by ScalaCheck as the grouping criterion for our data. Now we only have to slightly rewrite our property check to ensure that our ```collector``` function is called with each one of the input data:

```scala
object DataCollectionSpecificationWithCollect extends Properties("Grouping with collect") {
  property("Prop.collectwith a grouping function") = forAll { (r: Rectangle) =>
    collect(collector(r)) {
      r.areaCorrect == (r.width * r.height)
    }
  }
}
```

Now the console output is much more useful:

```
> Collected test data:
63% medium
24% large
13% small
```

The ```Prop.classify``` method offers similar features to ```Prop.collect``` but one key advantage of ```Prop.classify``` is that it allows multi-level grouping of data. In our example scenario, data could also be grouped based on whether the rectangle was wider or taller in addition to the size of its perimeter:

```scala
object DataCollectionWithGroupAndCollect extends Properties("Grouping with both") {
  property("Prop.classify with Prop.collect") = forAll { (r: Rectangle) =>
    classify(r.height > r.width, "taller", "wider") {
      collect(collector(r)) {
        r.areaCorrect == (r.width * r.height)
      }
    }
  }
}
```

The console output after running DataCollectionWithGroupAndCollect.check will be something like this:

```scala
\> Collected test data:
32% medium, taller
26% medium, wider
21% large, wider
10% large, taller
9% small, wider
2% small, taller
```

Here we’ve used the "binary" version of ```Prop.classify``` to classify our random rectangle objects into "taller" or "wider", and then with ```Prop.collect``` we’ve collected the data using our previous function. The output now is a two-level grouping of our data.

The previous example also shows how ```Prop.classify``` and ```Prop.collect``` can be combined within the same property check, and even multiple calls can be nested to obtain a more granular classification (this is because according to their method signature, ```Prop.classify``` and ```Prop.collect``` return a ```Prop``` object, and ```Prop``` objects can be chained).

All in all, both ```classify``` and ```collect``` provide powerful mechanisms to examine the distribution of the random data being used by ScalaCheck for testing our property checks.
